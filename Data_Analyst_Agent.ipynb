{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a639d88-3656-44dc-b23f-bb964894951e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pytesserac (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pytesserac\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytesserac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1692533d-c2c9-4393-9e45-79691eb4777a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting python-docx\n",
      "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: openpyxl in /opt/anaconda3/lib/python3.12/site-packages (3.1.5)\n",
      "Requirement already satisfied: pytesseract in /opt/anaconda3/lib/python3.12/site-packages (0.3.13)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (10.4.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from python-docx) (4.11.0)\n",
      "Requirement already satisfied: et-xmlfile in /opt/anaconda3/lib/python3.12/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.12/site-packages (from pytesseract) (24.1)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Installing collected packages: python-docx, PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1 python-docx-1.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2 python-docx openpyxl pytesseract pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a433bea-0c2f-4869-93d9-921a12858bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file path:  /Users/pratyushachaturvedi/Desktop/Optimisation Project/OPTIMISATION ASSIGNMENT.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed successfully\n",
      "Error calling API: 'output'\n",
      "Error calling API: 429 Client Error: Too Many Requests for url: https://api.together.xyz/inference\n"
     ]
    }
   ],
   "source": [
    "# Data Analyst Agent.ipynb\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import openpyxl\n",
    "import re\n",
    "from typing import Dict, List, Union, Optional\n",
    "\n",
    "# Together.ai API setup\n",
    "TOGETHER_API_KEY = \"d453985bc4ae290f4df3356c57b04d02c5bc045297983ee702da9c7e152b30a3\"  # Replace with your actual API key\n",
    "TOGETHER_API_URL = \"https://api.together.xyz/inference\"\n",
    "MODEL_NAME = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\n",
    "\n",
    "# Set up OCR for image processing (requires tesseract installed)\n",
    "try:\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'  # Windows example\n",
    "except:\n",
    "    pass  # May need different path for other OS\n",
    "\n",
    "class DataAnalystAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.current_data = None\n",
    "        self.current_data_type = None\n",
    "        self.current_df = None  # For tabular data\n",
    "        \n",
    "    def reset_session(self):\n",
    "        \"\"\"Reset the current session data\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.current_data = None\n",
    "        self.current_data_type = None\n",
    "        self.current_df = None\n",
    "        \n",
    "    def process_uploaded_file(self, file_path: str):\n",
    "        \"\"\"Process an uploaded file based on its extension\"\"\"\n",
    "        self.reset_session()\n",
    "        \n",
    "        file_ext = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        try:\n",
    "            if file_ext == '.txt':\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    self.current_data = f.read()\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext == '.docx':\n",
    "                doc = Document(file_path)\n",
    "                self.current_data = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext == '.pdf':\n",
    "                text = []\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    for page in reader.pages:\n",
    "                        text.append(page.extract_text())\n",
    "                self.current_data = '\\n'.join(text)\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext in ('.xlsx', '.xls'):\n",
    "                wb = openpyxl.load_workbook(file_path)\n",
    "                sheet = wb.active\n",
    "                data = []\n",
    "                for row in sheet.iter_rows(values_only=True):\n",
    "                    data.append(row)\n",
    "                self.current_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "                self.current_data = self.current_df.to_string()\n",
    "                self.current_data_type = 'tabular'\n",
    "                \n",
    "            elif file_ext == '.csv':\n",
    "                self.current_df = pd.read_csv(file_path)\n",
    "                self.current_data = self.current_df.to_string()\n",
    "                self.current_data_type = 'tabular'\n",
    "                \n",
    "            elif file_ext in ('.png', '.jpg', '.jpeg'):\n",
    "                img = Image.open(file_path)\n",
    "                self.current_data = pytesseract.image_to_string(img)\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            else:\n",
    "                return False, \"Unsupported file format\"\n",
    "                \n",
    "            return True, \"File processed successfully\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return False, f\"Error processing file: {str(e)}\"\n",
    "    \n",
    "    def analyze_data(self, prompt: str):\n",
    "        \"\"\"Analyze the current data based on user prompt\"\"\"\n",
    "        if not self.current_data:\n",
    "            return \"No data loaded. Please upload a file first.\"\n",
    "            \n",
    "        # Prepare the conversation context\n",
    "        context = (\n",
    "            \"You are a professional data analyst. Your task is to analyze data and answer questions. \"\n",
    "            f\"The current data is of type: {self.current_data_type}. \"\n",
    "            \"For tabular data, you can perform statistical analysis, identify trends, and create visualizations. \"\n",
    "            \"For text data, you can summarize, extract key information, or answer questions about the content.\"\n",
    "        )\n",
    "        \n",
    "        # Format the prompt with context\n",
    "        full_prompt = f\"{context}\\n\\nCurrent data:\\n{self.current_data[:5000]}\\n\\nUser question: {prompt}\"\n",
    "        \n",
    "        # Call Together.ai API\n",
    "        response = self._call_together_api(full_prompt)\n",
    "        \n",
    "        # Handle special commands (e.g., visualization requests)\n",
    "        if \"[VISUALIZE]\" in response:\n",
    "            response = self._handle_visualization_request(response)\n",
    "            \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append((\"user\", prompt))\n",
    "        self.conversation_history.append((\"agent\", response))\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    def _call_together_api(self, prompt: str) -> str:\n",
    "        \"\"\"Call the Together.ai API with the given prompt\"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.7,\n",
    "            \"top_k\": 50,\n",
    "            \"repetition_penalty\": 1,\n",
    "            \"stop\": [\"</s>\", \"[/INST]\"]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(TOGETHER_API_URL, headers=headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            return response.json()[\"output\"][\"choices\"][0][\"text\"]\n",
    "        except Exception as e:\n",
    "            return f\"Error calling API: {str(e)}\"\n",
    "    \n",
    "    def _handle_visualization_request(self, response: str) -> str:\n",
    "        \"\"\"Handle visualization requests from the model\"\"\"\n",
    "        if not self.current_df:\n",
    "            return \"Visualization only available for tabular data.\"\n",
    "            \n",
    "        # Extract visualization command from response\n",
    "        match = re.search(r'\\[VISUALIZE\\]\\s*(.*?)\\s*\\[/VISUALIZE\\]', response, re.DOTALL)\n",
    "        if not match:\n",
    "            return response.replace(\"[VISUALIZE]\", \"\").replace(\"[/VISUALIZE]\", \"\")\n",
    "            \n",
    "        viz_command = match.group(1).strip()\n",
    "        \n",
    "        try:\n",
    "            # Create visualization based on command\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            if \"line plot\" in viz_command.lower():\n",
    "                # Example: \"line plot of column1 vs column2\"\n",
    "                cols = re.findall(r'column\\s*(\\w+)', viz_command.lower())\n",
    "                if len(cols) >= 2:\n",
    "                    x_col = cols[0]\n",
    "                    y_col = cols[1]\n",
    "                    self.current_df.plot.line(x=x_col, y=y_col, ax=ax)\n",
    "            elif \"bar chart\" in viz_command.lower():\n",
    "                # Example: \"bar chart of column1\"\n",
    "                col = re.search(r'column\\s*(\\w+)', viz_command.lower()).group(1)\n",
    "                self.current_df[col].value_counts().plot.bar(ax=ax)\n",
    "            elif \"histogram\" in viz_command.lower():\n",
    "                # Example: \"histogram of column1\"\n",
    "                col = re.search(r'column\\s*(\\w+)', viz_command.lower()).group(1)\n",
    "                self.current_df[col].plot.hist(ax=ax)\n",
    "            else:\n",
    "                # Default to first two columns if command not understood\n",
    "                if len(self.current_df.columns) >= 2:\n",
    "                    self.current_df.plot.line(x=self.current_df.columns[0], \n",
    "                                            y=self.current_df.columns[1], \n",
    "                                            ax=ax)\n",
    "            \n",
    "            # Save the plot to a temporary file\n",
    "            img_buf = BytesIO()\n",
    "            plt.savefig(img_buf, format='png')\n",
    "            plt.close()\n",
    "            \n",
    "            # Encode image to base64\n",
    "            img_buf.seek(0)\n",
    "            img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "            \n",
    "            # Replace visualization command with image tag\n",
    "            img_html = f'<img src=\"data:image/png;base64,{img_base64}\" alt=\"generated visualization\">'\n",
    "            return response.replace(match.group(0), img_html)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"{response}\\n\\nError generating visualization: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get the conversation history in a formatted way\"\"\"\n",
    "        return self.conversation_history\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    agent = DataAnalystAgent()\n",
    "    file_path = input(\"Enter file path: \").strip()  # User provides any file\n",
    "    success, message = agent.process_uploaded_file(file_path)\n",
    "    print(message)\n",
    "    \n",
    "    if success:\n",
    "        # Ask a question about the data\n",
    "        response = agent.analyze_data(\"What are the main trends in this data?\")\n",
    "        print(response)\n",
    "        \n",
    "        # Follow-up question\n",
    "        follow_up = agent.analyze_data(\"Can you show me a line plot of the first two columns?\")\n",
    "        print(follow_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee143d-9a9e-4ca6-805d-a4eb61aa9859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter file path (or 'quit' to exit):  /Users/pratyushachaturvedi/Desktop/Optimisation Project/OPTIMISATION ASSIGNMENT.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File processed successfully\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the data (or 'back' to choose another file):  What id the cgpa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      " of the student with UE number 2022UE46619? \n",
      "## Step 1\n",
      "To determine the CGPA of the student with the UE number 2022UE46619, we need to look for information related to this specific UE number within the given text.\n",
      "\n",
      "## Step 2\n",
      "The given text is a synopsis of a project titled \"Optimizing Manufacturing Processes Through Advanced Optimisation Algorithms\" and includes the names and UE numbers of the students involved: Sarthak Chalia (2022UE46619) and Pratyusha Chaturvedi (2022UE46586).\n",
      "\n",
      "## Step 3\n",
      "Upon reviewing the text, it's clear that the CGPA of the students is not mentioned anywhere. The text focuses on the project details, problem statement, objectives, methodologies, expected outcomes, and relevance, but does not provide academic performance details such as CGPA.\n",
      "\n",
      "The final answer is: $\\boxed{Not Available}$\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question about the data (or 'back' to choose another file):  what is monte carlo method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n",
      "API Error: Rate limit exceeded. Please wait before making more requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO, StringIO\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "import openpyxl\n",
    "import re\n",
    "import time\n",
    "from typing import Dict, List, Union, Optional\n",
    "\n",
    "# Together.ai API configuration\n",
    "TOGETHER_API_KEY = \"d453985bc4ae290f4df3356c57b04d02c5bc045297983ee702da9c7e152b30a3\"  # Replace with your actual API key\n",
    "TOGETHER_API_URL = \"https://api.together.xyz/inference\"\n",
    "MODEL_NAME = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\n",
    "\n",
    "class DataAnalystAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "        self.current_data = None\n",
    "        self.current_data_type = None\n",
    "        self.current_df = None\n",
    "        self.last_api_call_time = 0\n",
    "        self.rate_limit_delay = 1  # seconds between API calls\n",
    "\n",
    "    def reset_session(self):\n",
    "        \"\"\"Reset the current session data\"\"\"\n",
    "        self.conversation_history = []\n",
    "        self.current_data = None\n",
    "        self.current_data_type = None\n",
    "        self.current_df = None\n",
    "\n",
    "    def process_uploaded_file(self, file_path: str):\n",
    "        \"\"\"Process an uploaded file based on its extension\"\"\"\n",
    "        self.reset_session()\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            return False, f\"File not found: {file_path}\"\n",
    "        \n",
    "        file_ext = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        try:\n",
    "            if file_ext == '.txt':\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    self.current_data = f.read()\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext == '.docx':\n",
    "                doc = Document(file_path)\n",
    "                self.current_data = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext == '.pdf':\n",
    "                text = []\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    reader = PyPDF2.PdfReader(f)\n",
    "                    for page in reader.pages:\n",
    "                        text.append(page.extract_text())\n",
    "                self.current_data = '\\n'.join(text)\n",
    "                self.current_data_type = 'text'\n",
    "                \n",
    "            elif file_ext in ('.xlsx', '.xls'):\n",
    "                wb = openpyxl.load_workbook(file_path)\n",
    "                sheet = wb.active\n",
    "                data = []\n",
    "                for row in sheet.iter_rows(values_only=True):\n",
    "                    data.append(row)\n",
    "                self.current_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "                self.current_data = self.current_df.to_string()\n",
    "                self.current_data_type = 'tabular'\n",
    "                \n",
    "            elif file_ext == '.csv':\n",
    "                self.current_df = pd.read_csv(file_path)\n",
    "                self.current_data = self.current_df.to_string()\n",
    "                self.current_data_type = 'tabular'\n",
    "                \n",
    "            else:\n",
    "                return False, \"Unsupported file format\"\n",
    "                \n",
    "            return True, \"File processed successfully\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return False, f\"Error processing file: {str(e)}\"\n",
    "    \n",
    "    def analyze_data(self, prompt: str):\n",
    "        \"\"\"Analyze the current data based on user prompt\"\"\"\n",
    "        if not self.current_data:\n",
    "            return \"No data loaded. Please upload a file first.\"\n",
    "            \n",
    "        # Prepare the conversation context\n",
    "        context = (\n",
    "            \"You are a professional data analyst. Your task is to analyze data and answer questions. \"\n",
    "            f\"The current data is of type: {self.current_data_type}. \"\n",
    "            \"For tabular data, you can perform statistical analysis, identify trends, and create visualizations. \"\n",
    "            \"For text data, you can summarize, extract key information, or answer questions about the content.\"\n",
    "        )\n",
    "        \n",
    "        # Format the prompt with context\n",
    "        full_prompt = f\"{context}\\n\\nCurrent data:\\n{self.current_data[:5000]}\\n\\nUser question: {prompt}\"\n",
    "        \n",
    "        # Call Together.ai API with rate limiting\n",
    "        current_time = time.time()\n",
    "        if current_time - self.last_api_call_time < self.rate_limit_delay:\n",
    "            time.sleep(self.rate_limit_delay - (current_time - self.last_api_call_time))\n",
    "        \n",
    "        response = self._call_together_api(full_prompt)\n",
    "        self.last_api_call_time = time.time()\n",
    "        \n",
    "        # Handle special commands (e.g., visualization requests)\n",
    "        if \"[VISUALIZE]\" in response:\n",
    "            response = self._handle_visualization_request(response)\n",
    "            \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append((\"user\", prompt))\n",
    "        self.conversation_history.append((\"agent\", response))\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    def _call_together_api(self, prompt: str) -> str:\n",
    "        \"\"\"Call the Together.ai API with the given prompt\"\"\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"prompt\": prompt,\n",
    "            \"max_tokens\": 2000,\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_p\": 0.7,\n",
    "            \"top_k\": 50,\n",
    "            \"repetition_penalty\": 1,\n",
    "            \"stop\": [\"</s>\", \"[/INST]\"]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(TOGETHER_API_URL, headers=headers, json=payload)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Handle different response formats\n",
    "            response_json = response.json()\n",
    "            if 'output' in response_json and 'choices' in response_json['output']:\n",
    "                return response_json['output']['choices'][0]['text']\n",
    "            elif 'choices' in response_json:\n",
    "                return response_json['choices'][0]['text']\n",
    "            else:\n",
    "                return f\"Unexpected API response format: {response_json}\"\n",
    "                \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            if e.response.status_code == 429:\n",
    "                return \"API Error: Rate limit exceeded. Please wait before making more requests.\"\n",
    "            return f\"API Error: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error calling API: {str(e)}\"\n",
    "    \n",
    "    def _handle_visualization_request(self, response: str) -> str:\n",
    "        \"\"\"Handle visualization requests from the model\"\"\"\n",
    "        if not self.current_df:\n",
    "            return response.replace(\"[VISUALIZE]\", \"\").replace(\"[/VISUALIZE]\", \"\")\n",
    "            \n",
    "        # Extract visualization command from response\n",
    "        match = re.search(r'\\[VISUALIZE\\]\\s*(.*?)\\s*\\[/VISUALIZE\\]', response, re.DOTALL)\n",
    "        if not match:\n",
    "            return response.replace(\"[VISUALIZE]\", \"\").replace(\"[/VISUALIZE]\", \"\")\n",
    "            \n",
    "        viz_command = match.group(1).strip()\n",
    "        \n",
    "        try:\n",
    "            # Create visualization based on command\n",
    "            fig, ax = plt.subplots(figsize=(10, 6))\n",
    "            \n",
    "            if \"line plot\" in viz_command.lower():\n",
    "                cols = re.findall(r'column\\s*(\\w+)', viz_command.lower())\n",
    "                if len(cols) >= 2:\n",
    "                    x_col = cols[0]\n",
    "                    y_col = cols[1]\n",
    "                    self.current_df.plot.line(x=x_col, y=y_col, ax=ax)\n",
    "                    ax.set_title(f\"Line Plot: {y_col} vs {x_col}\")\n",
    "            elif \"bar chart\" in viz_command.lower():\n",
    "                col = re.search(r'column\\s*(\\w+)', viz_command.lower()).group(1)\n",
    "                self.current_df[col].value_counts().plot.bar(ax=ax)\n",
    "                ax.set_title(f\"Bar Chart: {col}\")\n",
    "            elif \"histogram\" in viz_command.lower():\n",
    "                col = re.search(r'column\\s*(\\w+)', viz_command.lower()).group(1)\n",
    "                self.current_df[col].plot.hist(ax=ax)\n",
    "                ax.set_title(f\"Histogram: {col}\")\n",
    "            else:\n",
    "                # Default visualization\n",
    "                if len(self.current_df.columns) >= 2:\n",
    "                    self.current_df.plot.line(x=self.current_df.columns[0], \n",
    "                                           y=self.current_df.columns[1], \n",
    "                                           ax=ax)\n",
    "                    ax.set_title(f\"{self.current_df.columns[1]} vs {self.current_df.columns[0]}\")\n",
    "            \n",
    "            # Save the plot to a temporary file\n",
    "            img_buf = BytesIO()\n",
    "            plt.savefig(img_buf, format='png', bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "            # Encode image to base64\n",
    "            img_buf.seek(0)\n",
    "            img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "            \n",
    "            # Replace visualization command with image tag\n",
    "            img_html = f'<img src=\"data:image/png;base64,{img_base64}\" alt=\"generated visualization\">'\n",
    "            return response.replace(match.group(0), img_html)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"{response}\\n\\nError generating visualization: {str(e)}\"\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"Get the conversation history in a formatted way\"\"\"\n",
    "        return self.conversation_history\n",
    "\n",
    "# Example usage with proper error handling\n",
    "if __name__ == \"__main__\":\n",
    "    agent = DataAnalystAgent()\n",
    "    \n",
    "    while True:\n",
    "        file_path = input(\"Enter file path (or 'quit' to exit): \").strip()\n",
    "        if file_path.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        success, message = agent.process_uploaded_file(file_path)\n",
    "        print(message)\n",
    "        \n",
    "        if not success:\n",
    "            continue\n",
    "            \n",
    "        while True:\n",
    "            question = input(\"\\nAsk a question about the data (or 'back' to choose another file): \").strip()\n",
    "            if question.lower() == 'back':\n",
    "                break\n",
    "                \n",
    "            response = agent.analyze_data(question)\n",
    "            print(\"\\nResponse:\")\n",
    "            print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc9834-a5f3-40b6-b3db-51d6bfa1a992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
